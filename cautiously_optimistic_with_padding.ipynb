{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanKaplan999/graph-transfer/blob/main/cautiously_optimistic_with_padding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "    return version.split('+')[0]\n",
        "\n",
        "def format_cuda_version(version):\n",
        "    return 'cu' + version.replace('.', '')\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)"
      ],
      "metadata": {
        "id": "mc1ptwP5xHwq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkU1ucn9xFtC",
        "outputId": "92da2506-57b0-4872-f0d7-d2a3c91d42d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.15)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.1.0.post1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.7/dist-packages (2.1.0.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.0.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric\n",
        "\n",
        "torch_geometric.__version__\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nPgvoKnlyEGN",
        "outputId": "2a5cea46-a55b-46d1-9f92-7fd4c37c78e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download our dataset:"
      ],
      "metadata": {
        "id": "syreQQJYvvsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import I\n",
        "from torch_geometric.data import Data \n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "dataset = TUDataset(root='/tmp/AIDS', name='AIDS')\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "# takes way too long\n",
        "#dataset = TUDataset(root='/tmp/FRANKENSTEIN', name='FRANKENSTEIN') \n",
        "#dataset = dataset.shuffle()\n",
        "\n",
        "# enzymes works ok (much fewer examples, but 6 classes) gets regularly above 20%, its at least better than guessing\n",
        "#dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
        "#dataset = dataset.shuffle()\n",
        "\n",
        "#this one has 100 classes\n",
        "#dataset = TUDataset(root='/tmp/COIL-DEL', name='COIL-DEL')\n",
        "#dataset = dataset.shuffle()\n",
        "\n",
        "# to divide evenly, make sure it's divisible by 32\n",
        "dataset = dataset[(len(dataset) % 32):]\n",
        "\n",
        "print(dataset)\n",
        "print(\"length of set\", len(dataset))\n",
        "print(\"# of classes\", dataset.num_classes)\n",
        "\n",
        "max = 0\n",
        "for data in dataset:\n",
        "  if len(data.x) > max:\n",
        "    max = len(data.x)\n",
        "print(\"Max size of adjacency matrix:\", max, \"x\", max)\n"
      ],
      "metadata": {
        "id": "54aTQ2Utyaa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f27d22d-baf2-44f0-e4d6-f6b0438bd512"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/AIDS.zip\n",
            "Extracting /tmp/AIDS/AIDS/AIDS.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AIDS(1984)\n",
            "length of set 1984\n",
            "# of classes 2\n",
            "Max size of adjacency matrix: 95 x 95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct all of our \"images\""
      ],
      "metadata": {
        "id": "vR9YRUuqwJ2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Initializing graph to image\")\n",
        "\n",
        "# convert our graph data to \"images\" containing the adjacency matrix\n",
        "images = []\n",
        "\n",
        "for j in range(len(dataset)):\n",
        "\n",
        "    graph = dataset[j]\n",
        "\n",
        "    adj_matrix = np.zeros([3, 224, 224])\n",
        "\n",
        "    num_nodes = len(graph.x)\n",
        "    num_edges = len(graph.edge_index[0])\n",
        "    offset = int((224 - num_nodes) / 2)\n",
        "\n",
        "    # for each edge, initialize its entry in the adjaceny matrix as a colored pixel\n",
        "    for i in range(num_edges):\n",
        "      x = graph.edge_index[0][i]\n",
        "      y = graph.edge_index[1][i]\n",
        "      adj_matrix[0][offset + x][offset + y] = 1\n",
        "      adj_matrix[1][offset + x][offset + y] = 1\n",
        "      adj_matrix[2][offset + x][offset + y] = 1\n",
        "\n",
        "    images.append((torch.from_numpy(adj_matrix), graph.y.item()))\n",
        "\n",
        "  # have to convert them to tensors so it actually works\n",
        "\n",
        "# splits it 90/10 train/test\n",
        "cutoff = int(len(images) * 0.9)\n",
        "training_data = images[:cutoff]\n",
        "test_data = images[cutoff:]\n",
        "\n",
        "print(len(images), 'total examples')\n",
        "print(len(training_data), \"training examples\")\n",
        "print(len(test_data), \"test examples\")\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4po1HaQ_-Cd",
        "outputId": "1622faa3-9572-4f3b-8b9f-cd625d04dada"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing graph to image\n",
            "1984 total examples\n",
            "1785 training examples\n",
            "199 test examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU availability\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {device} device')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0gufSkIPbWc",
        "outputId": "24ca3c93-fed0-4262-ba8e-d2455ac09d51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0 device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download our pretrained model:"
      ],
      "metadata": {
        "id": "tsgQ4vJQwUXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "imgClassifier = models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1').to(device)"
      ],
      "metadata": {
        "id": "fX5XCYEbAr6y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x is [1,3,224,224], mask is [4, 3, offset, offset]\n",
        "def pad(x, mask):\n",
        "  temp = x.numpy()\n",
        "  for i in range(224):\n",
        "    for j in range(224):\n",
        "      \n",
        "      if i < offset and j < offset:\n",
        "        temp[0][0][i][j] = mask[0][0][i][j]\n",
        "        temp[0][1][i][j] = mask[0][1][i][j]\n",
        "        temp[0][2][i][j] = mask[0][2][i][j]\n",
        "\n",
        "      if i > max + offset and j < offset:\n",
        "        temp[0][0][i][j] = mask[1][0][i - (max + offset)][j]\n",
        "        temp[0][1][i][j] = mask[1][1][i - (max + offset)][j]\n",
        "        temp[0][2][i][j] = mask[1][2][i - (max + offset)][j]\n",
        "      \n",
        "      if i < offset and j > max + offset:\n",
        "        temp[0][0][i][j] = mask[2][0][i][j - (max + offset)]\n",
        "        temp[0][1][i][j] = mask[2][1][i][j - (max + offset)]\n",
        "        temp[0][2][i][j] = mask[2][2][i][j - (max + offset)]\n",
        "      \n",
        "      if i > max + offset and j > max + offset:\n",
        "        temp[0][0][i][j] = mask[3][0][i - (max + offset)][j - (max + offset)]\n",
        "        temp[0][1][i][j] = mask[3][1][i - (max + offset)][j - (max + offset)]\n",
        "        temp[0][2][i][j] = mask[3][2][i - (max + offset)][j - (max + offset)]\n",
        "      \n",
        "      else:\n",
        "        temp[0][0][i][j] = x[0][0][i][j]\n",
        "        temp[0][1][i][j] = x[0][1][i][j]\n",
        "        temp[0][2][i][j] = x[0][2][i][j]\n",
        "  return temp\n",
        "\n",
        "\n",
        "x = np.zeros([1,3,224,224])\n",
        "x = torch.tensor(x)\n",
        "mask = np.ones([4, 3, offset, offset])\n",
        "mask = torch.tensor(mask)\n",
        "\n",
        "padded = pad(x, mask)\n",
        "\n",
        "print(\"max: \", max)\n",
        "print(\"offset:\", offset)\n",
        "print(padded[0][0][0][0])\n",
        "print(padded[0][0][offset + 5][offset + 5])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPBZiW5NtO_v",
        "outputId": "f1c9b10f-e573-401a-a641-cccc62314c14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max:  95\n",
            "offset: 106\n",
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # freeze ALL parameters\n",
        "        for param in imgClassifier.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "        #self.W = torch.nn.Parameter(torch.tensor((1000, dataset.num_classes), dtype=float)) # output transformation parameter \n",
        "        self.W = torch.nn.Parameter(torch.nn.init.uniform_(torch.empty(1000, dataset.num_classes))).to(device)\n",
        "\n",
        "        #print(self.W[0][0])\n",
        "\n",
        "        #b = torch.nn.Parameter(torch.tensor((dataset.num_classes, 1), dtype=float))\n",
        "        self.b = torch.nn.Parameter(torch.nn.init.uniform_(torch.empty(1, dataset.num_classes))).to(device)\n",
        "\n",
        "        # a mask parameter for each corner of the padded image, and each channel; [corner, channel, width, height] with corner=[1..4] going from upper left clockwise to lower left.\n",
        "        #Omega = torch.nn.Parameter(torch.tensor((4, 3, offset, offset), dtype=float)) \n",
        "        self.Omega = torch.nn.Parameter(torch.nn.init.uniform_(torch.empty(4, 3, offset, offset))).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.pad(x, self.Omega)\n",
        "        #z = torch.unsqueeze(z, 0) # size is [1,3,224,224]\n",
        "\n",
        "        z = z.float()\n",
        "    \n",
        "        out = imgClassifier(z) # size is [1,1000]\n",
        "\n",
        "        reducedOut = torch.matmul(out, self.W.to(device))      # size is [1, 100]\n",
        "        #reducedOut = torch.matmul(out, self.W)      # size is [1, 100]\n",
        "\n",
        "        #return F.log_softmax((reducedOut + self.b.to(device)), dim=0)\n",
        "        return F.log_softmax((reducedOut + self.b), dim=0)\n",
        "    \n",
        "    def pad(self, x, mask):\n",
        "      # if x is [batchsize, channels, width, height], this pads x with the mask\n",
        "      temp = x.cpu().numpy()\n",
        "      for i in range(224):\n",
        "        for j in range(224):\n",
        "          \n",
        "          if i < offset and j < offset:\n",
        "            temp[0][0][i][j] = mask[0][0][i][j]\n",
        "            temp[0][1][i][j] = mask[0][1][i][j]\n",
        "            temp[0][2][i][j] = mask[0][2][i][j]\n",
        "\n",
        "          if i > max + offset and j < offset:\n",
        "            temp[0][0][i][j] = mask[1][0][i - (max + offset)][j]\n",
        "            temp[0][1][i][j] = mask[1][1][i - (max + offset)][j]\n",
        "            temp[0][2][i][j] = mask[1][2][i - (max + offset)][j]\n",
        "          \n",
        "          if i < offset and j > max + offset:\n",
        "            temp[0][0][i][j] = mask[2][0][i][j - (max + offset)]\n",
        "            temp[0][1][i][j] = mask[2][1][i][j - (max + offset)]\n",
        "            temp[0][2][i][j] = mask[2][2][i][j - (max + offset)]\n",
        "          \n",
        "          if i > max + offset and j > max + offset:\n",
        "            temp[0][0][i][j] = mask[3][0][i - (max + offset)][j - (max + offset)]\n",
        "            temp[0][1][i][j] = mask[3][1][i - (max + offset)][j - (max + offset)]\n",
        "            temp[0][2][i][j] = mask[3][2][i - (max + offset)][j - (max + offset)]\n",
        "          \n",
        "          else:\n",
        "            temp[0][0][i][j] = x[0][0][i][j]\n",
        "            temp[0][1][i][j] = x[0][1][i][j]\n",
        "            temp[0][2][i][j] = x[0][2][i][j]\n",
        "\n",
        "      return torch.tensor(temp).to(device)\n",
        "\n",
        "\n",
        "# Example of applying to a single datapoint\n",
        "classifier = GCN()\n",
        "\n",
        "x = training_data[0][0] # x is a single input\n",
        "x = torch.unsqueeze(x, 0)\n",
        "x = x.float()\n",
        "\n",
        "print(x.size())\n",
        "\n",
        "yhat = classifier(x.to(device))\n",
        "print(yhat[0,0])\n",
        "#sum = 0\n",
        "#for i in range(100):\n",
        "#  sum += yhat[0][i]\n",
        "#print(sum)\n",
        "#print(torch.max(yhat))"
      ],
      "metadata": {
        "id": "WZAHm_fAAJeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cefcb66-f1ff-49f4-f367-7379d5a7c992"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 224, 224])\n",
            "tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Train\n",
        "model = GCN().to(device)\n",
        "\n",
        "# DataLoaders will return randomly shuffled minibatches in each epoch\n",
        "train_loader = DataLoader(training_data, batch_size=32, \n",
        "                              shuffle=True, num_workers=1)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=1)\n",
        "\n",
        "# Choose the optimizer\n",
        "#optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "optimizer = torch.optim.Adam(imgClassifier.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "# set the loss function\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "for batchnum, (X,y) in enumerate(train_loader):\n",
        "  if batchnum == 0:\n",
        "    print(y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6DL5VurQGck",
        "outputId": "2af22890-a93e-4e8a-a9ad-f547afc891ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Does one epoch of training\n",
        "\n",
        "train_loss_set , train_acc_set = [], []\n",
        "val_loss_set , val_acc_set = [], []\n",
        "\n",
        "def train_epoch(dataloader, model, criterion, optimizer):\n",
        "    \n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    train_loss, correct = 0, 0\n",
        "    \n",
        "    for batchnum, (X, y) in enumerate(dataloader):\n",
        "\n",
        "        X = X.to(device=device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Compute prediction and loss on the minibatch\n",
        "        yhat = model(X) \n",
        "        loss = criterion(yhat, y)\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        correct += (yhat.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    train_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Train Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
        "    train_loss_set.append(train_loss)\n",
        "    train_acc_set.append(100 * correct)\n",
        "\n",
        "            \n",
        "# Computes loss and accuracy on the validation set\n",
        "\n",
        "def validate(dataloader, model, criterion):\n",
        "    \n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad(): # we don't want to accumulate the gradients during validation\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            yhat = model(X)\n",
        "            test_loss += criterion(yhat, y).item()\n",
        "      \n",
        "            correct += (yhat.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    val_loss_set.append(test_loss)\n",
        "    val_acc_set.append(100 * correct)\n",
        "\n",
        "start = time.time()\n",
        "for t in range(10):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    model.train() # turn model to train mode (for dropout, etc)\n",
        "    train_epoch(train_loader, model, criterion, optimizer)\n",
        "    model.eval() # turn model to evaluation mode (for dropout, etc)\n",
        "    validate(test_loader, model, criterion)\n",
        "    \n",
        "print(\"Done!\")\n",
        "\n",
        "end = time.time()\n",
        "print(round(((end-start)/60),1) , 'minutes')\n",
        "\n",
        "print(\"Randomly guessing would be an accuracy of \", (1/dataset.num_classes) * 100)\n",
        "\n",
        "# plot our accuracy and loss\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_acc_set, color='green', label='train accuracy')\n",
        "plt.plot(val_acc_set, color='blue', label='validataion accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss_set, color='orange', label='train loss')\n",
        "plt.plot(val_loss_set, color='red', label='validataion loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKWPlLI3tU3X",
        "outputId": "4e191255-bfcf-4520-8fb3-158facbf49bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Train Error: \n",
            " Accuracy: 75.6%, Avg loss: 2.022582 \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 73.4%, Avg loss: 1.711738 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Train Error: \n",
            " Accuracy: 77.8%, Avg loss: 1.829175 \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 78.9%, Avg loss: 1.251122 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Train Error: \n",
            " Accuracy: 76.9%, Avg loss: 1.952076 \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 73.4%, Avg loss: 1.836023 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Train Error: \n",
            " Accuracy: 71.7%, Avg loss: 2.161892 \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss: 2.137464 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Train Error: \n",
            " Accuracy: 74.3%, Avg loss: 1.984501 \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 76.9%, Avg loss: 1.194492 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Train Error: \n",
            " Accuracy: 77.7%, Avg loss: 1.949192 \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 78.9%, Avg loss: 1.433545 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Train Error: \n",
            " Accuracy: 73.4%, Avg loss: 1.920691 \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 66.3%, Avg loss: 2.268682 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Train Error: \n",
            " Accuracy: 74.5%, Avg loss: 2.028100 \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 72.4%, Avg loss: 1.620135 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Train Error: \n",
            " Accuracy: 72.5%, Avg loss: 2.179897 \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 65.3%, Avg loss: 2.192393 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Train Error: \n",
            " Accuracy: 73.0%, Avg loss: 2.083691 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}